total_storage_limit: 2000M

queue:
- name: etl-ndt-queue
  target: etl-ndt-parser
  # Average rate at which to release tasks to the service.  Default is 5/sec
  # This is actually the rate at which tokens are added to the bucket.
  # 1.0 allow processing a day's data (about 11K tasks) in 3 to 4 hours.
  rate: 1.0/s
  # Number of tokens that can accumulate in the bucket.  Default is 5.  This should
  # have very little impact for our environment.
  bucket_size: 10
  # Maximum number of concurrent requests.
  max_concurrent_requests: 360

# BigQuery has a streaming insert quota per table, which we seem to hit
# at around 3.0 tasks/second.  For processing archival data, we want to
# be able to process roughly one month per day.  At 16K tasks per day,
# this is about 500K tasks per input month, 20K tasks per processing hour,
# or just under 6 tasks/second.   
# When reprocessing data older than 30 days, the pipeline inserts rows 
# into templated tables, which means there is a separate table per day.
# So, we can exceed the 3 tasks/second rate if we have multiple queues,
# feed each table from a single queue, and rate limit each queue to
# less than 3 tasks/second.
# Below we create 7 queues, one for each day of the week.  This allows
# us, for example, to process 7 days concurrently, into seven distinct
# tables.  We can put multiple weeks of data into the queues as well. 
#
# This will be used in conjunction with a batch reprocessing script
# that will spray the requested tasks, by date, across the different
# queues.
# Since each queue is rate limited to 1 task/sec, and any given table
# receives data from a single day, and any given day's data will be
# directed to a single queue, this will limit the insert rate into 
# any single table to well below the table quota.
#
# The current pipeline config has up to 50 instances with 2 cpus and
# 12 workers each.  We allow a total of 560 (80 * 7) concurrent tasks,
# which should result in relatively few rejected requests once App
# Engine fully scales up.
# Some adjustments may be needed once this is running regularly.
- name: etl-ndt-batch-monday
  target: etl-ndt-batch-parser
  rate: 1.0/s
  bucket_size: 10
  max_concurrent_requests: 80

- name: etl-ndt-batch-tuesday
  target: etl-ndt-batch-parser
  rate: 1.0/s
  bucket_size: 10
  max_concurrent_requests: 80

- name: etl-ndt-batch-wednesday
  target: etl-ndt-batch-parser
  rate: 1.0/s
  bucket_size: 10
  max_concurrent_requests: 80

- name: etl-ndt-batch-thursday
  target: etl-ndt-batch-parser
  rate: 1.0/s
  bucket_size: 10
  max_concurrent_requests: 80

- name: etl-ndt-batch-friday
  target: etl-ndt-batch-parser
  rate: 1.0/s
  bucket_size: 10
  max_concurrent_requests: 80

- name: etl-ndt-batch-saturday
  target: etl-ndt-batch-parser
  rate: 1.0/s
  bucket_size: 10
  max_concurrent_requests: 80

- name: etl-ndt-batch-sunday
  target: etl-ndt-batch-parser
  rate: 1.0/s
  bucket_size: 10
  max_concurrent_requests: 80

- name: etl-traceroute-queue
  target: etl-traceroute-parser
  # Average rate at which to release tasks to the service.  Default is 5/sec
  # This is actually the rate at which tokens are added to the bucket.
  rate: 1.5/s
  # Number of tokens that can accumulate in the bucket.  Default is 5.  This should
  # have very little impact for our environment.
  bucket_size: 10
  # Maximum number of concurrent requests.
  max_concurrent_requests: 360

- name: etl-sidestream-queue
  target: etl-sidestream-parser
  # Average rate at which to release tasks to the service.  Default is 5/sec
  # This is actually the rate at which tokens are added to the bucket.
  rate: 1.5/s
  # Number of tokens that can accumulate in the bucket.  Default is 5.  This should
  # have very little impact for our environment.
  bucket_size: 10
  # Maximum number of concurrent requests.
  max_concurrent_requests: 180

- name: etl-disco-queue
  target: etl-disco-parser
  # Average rate at which to release tasks to the service.  Default is 5/sec
  # This is actually the rate at which tokens are added to the bucket.
  rate: 5/s
  # Number of tokens that can accumulate in the bucket.  Default is 5.  This should
  # have very little impact for our environment.
  bucket_size: 10
  # Maximum number of concurrent requests.
  max_concurrent_requests: 180

