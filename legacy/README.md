# Legacy schema and scripts.

Scripts and schema for handling legacy ndt tables generated by internal
pipeline.  These were originally stored in dremel and used the plx bridge
to provide a bigquery interface.

common.json specifies a common schema that has all of the non-empty
legacy plx fields, and adds fields introduced with the ETL pipeline
schema.  The legacy fields differ only in making the top level log_time
into a timestamp, for ease of use and compatibility with the new
schema.  Note, however, that the log_time field is missing from MANY
legacy table rows.

The convert-legacy-to-common.sh script is used to copy a single day
from the old plx tables into a new, partitioned
measurement-lab:legacy.ndt table.  It provides the explicit interleaving
of legacy and new schema fields, generally adding null values to the
new fields, with a couple exceptions where the syntax would be excessively
verbose (task_filename and parse_time).

The convert-all.sh script runs copy queries for an entire year.  It
requests copies for 31 days each month, so months with fewer than 31 days __will exhibit failures__ for the days that don't exist.
These show up as 'Invalid timestamp string' errors.

The script
runs a whole month of queries in parallel, then does a __wait__ for
all of them to complete before starting the next month.

The conversion queries are submitted as synchronous batch mode queries,
and may take some time to complete.  Single queries typically take
about a minute to process, but bigquery queues them up and processes
a few at a time in parallel.  It may take on the order of an hour to
process a full year's worth of queries.

To check status, use:
```bash
> bq ls -j -n 400 
```


## Data

Note that the partition_date field should not be relied on.  It was added
early in development, and overlooked later when it was no longer needed.
partition_date should instead be derived from the legacy.ndt _partition_time
field.